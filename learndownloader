#!/bin/bash

# Usage:
# learn_downloader "curl command"

mkdir -p $HOME/.cache/learn_downloader
cachedir="$HOME/.cache/learn_downloader"

curl_command="$@"

echo "Getting HTML page..."
bash -c "$curl_command -s --compressed" > $cachedir/tmp.html

cookies=$(echo "$curl_command" | grep -oP "\-H 'Cookie:.*?'")
useragent=$(echo "$curl_command" | grep -oP "\-H 'User-Agent:.*?'")

echo "Retrieving urls..."
grep -o 'href="https://learn.univpm.it/mod/resource/view.php?id\=[0-9]*"' $cachedir/tmp.html | sed 's/href=//' | tr -d '"' > $cachedir/urls.txt

rm $cachedir/finalurls.txt
while read url; do
	bash -c "curl $url $cookies $useragent -kIs -w %{redirect_url} -o /dev/null" >> $cachedir/finalurls.txt
	echo "" >> $cachedir/finalurls.txt
done < "$cachedir/urls.txt"

echo "Downloading files..."
count=0
while read finalurl; do
	filename=$(echo "$finalurl" | sed "s/^.*\///" | sed "s/%20/_/g" | sed "s/\?.*$//")
	bash -c "curl -s $finalurl $cookies $useragent -o $filename"
	count=$((count+1))
done < "$cachedir/finalurls.txt"

echo "$count file downloaded."
